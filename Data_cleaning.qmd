---
title: "Data cleaning"
author: "Arthur Lemoine & Matteo Boyer-Wright"
format: html
execute: 
  warning: false
  error: false
---
## Link of the project

https://github.com/arthurlemoine/final_project.git

## Link to the data and how to download it

### Warning

The main datasets used for this project exceed the Github file size limit (100MB). Therefore they cannot be included in the repository. 

To reproduce our work please download and save the following files in a folder named "data" in your own repository.  

### UK real estate transactions

http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv

Note that this is the complete dataset (1995-2022) and it is particularly heavy (28M observations / ~4.7Go)

If you just want to have an idea about what our code look like you can always use the 'rd_df.csv' dataset (which is a random sample of 10 000 lines).

### Postcode to MLSOA (Middle Layer Super Output Area)

https://www.arcgis.com/sharing/rest/content/items/3770c5e8b0c24f1dbe6d2fc6b46a0b18/data

This file will be used to combine datasets with different geographical scales. 
Save it as 'postcode_to_area.csv'.

### Income, pollution and population

Those datasets (pre-processed) are available directly from our Github. 
If you want the raw initial data please download and merge the following datasets. 

- Pollution:

* https://compliance-data.defra.gov.uk/datasets/Defra::pm10-annual-mean-local-authority-2020/
* https://compliance-data.defra.gov.uk/datasets/Defra::pm10-annual-mean-local-authority-2021/
* https://compliance-data.defra.gov.uk/datasets/Defra::pm10-annual-mean-local-authority-2022/

- Population:

* https://www.nomisweb.co.uk/census/2011/postcode_headcounts_and_household_estimates

At the time we are writting this, we are still waiting for the data from the 2021 census to be available. 

- Income:

* https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2020/saiefy1920finalqaddownload280923.xlsx

/!\ This is not available as .csv so you need to save the Excel worksheet 'Total annual income' as a .csv file.

* https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2018/totalannualincome2018.csv
* https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2016/1totalannualincome.csv
* https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2014/1totalweeklyincome.csv
* https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/201112/1totalweeklyincome.csv

## Description of the sources

The real estate transactions data is issued by the HM Land Registry, a non-ministerial government department whose goal is to provide a reliable record of information about real estate ownership and land titles in England and Wales.

The data linking the postcode to the MSOA is issued by the Office for National Statistics (ONS) which collects, analyses and disseminates statistics about the UK's economy, society and population. More specifically, the dataset is provided by the geography department of the ONS which is in charge of the framework of territorial units, boundaries and maps that provide the structure for collecting, processing, storing and aggregating data.

The population data is also issued by the ONS that was recorded as part of the 2011 Census. It covers the whole range of population characteristics and subject areas.

The income data is provided as well by the ONS, through bulletin published every two years which looks at the mean household disposable (net) income for middle layer super output areas (MSOAs) in England and Wales.

Eventually, the air pollution data is provided by UK-AIR, a body in charge of monitoring air quality in the UK on behalf of the UK Department for Environment, Food & Rural Affairs and the Devolved Administrations.

## Loading libraries

```{r}
#| echo: false

library(dplyr)
library(tidyr)
library(here)
library(vroom)
library(lubridate)
library(ggplot2)
library(stringr)
library(knitr)
library(zoo)

here::i_am('final_project.Rproj')
```

## Loading data

### Optional - load full transaction dataset

```{r}
#| eval: true

df <- vroom(here("data", "pp-complete.csv"), col_names = FALSE)

df <- df |>
  rename("unique_id" = 1,
         "price_paid" = 2,
         "deed_date" = 3,
         "postcode" = 4,
         "property_type" = 5,
         "new_build" = 6,
         "estate_type" = 7,
         "saon" = 8,
         "paon" = 9,
         "street" = 10,
         "locality" = 11,
         "town" = 12,
         "district" = 13,
         "county" = 14,
         "transaction_category" = 15,
         "linked_data_uri" = 16)

df <- df |> 
  mutate(deed_date = lubridate::ymd(deed_date))

df <- df |> 
  mutate(year = as.numeric(format(deed_date, format="%Y")), 
         month = as.numeric(format(deed_date, format="%m")))

#rd_df <- sample_n(df, 10000)  #Uncomment if you want to redraw a sample of the data

df <- df |>
  select(-1,-unique_id, -linked_data_uri) 
```

### Alternative - load random sample (10 000 lines)

```{r}
#| eval: false
df <- vroom(here("data", "rd_df.csv"))
df <- df |>
  select(-1,-unique_id, -linked_data_uri) 
```

### Income data

```{r}
#| echo: false

income1112 <- vroom(here("data", "income1112.csv"), skip = 5, col_names = FALSE)
income1314 <- vroom(here("data", "income1314.csv"), skip = 5, col_names = FALSE)
income1516 <- vroom(here("data", "income1516.csv"), skip = 5, col_names = FALSE, col_select = -c(11:14))
income1718 <- vroom(here("data", "income1718.csv"), skip = 5, col_names = FALSE)
income1920 <- vroom(here("data", "income1920.csv"), skip = 5, col_names = FALSE, delim = ";")
```

Data from years 2011/2012 and 2013/2014 are recorded as weekly and need to be transformed to annual. 
```{r}
income1112[,c(7:10)] <- income1112[,c(7:10)]*52
income1314[,c(7:10)] <- income1314[,c(7:10)]*52
```

Fixing issue with Excel export introducing a blank space after the thousands.
```{r}
income1920 <- income1920 %>%
  mutate(X7 = str_replace_all(X7," ","")) %>%
  mutate(X8 = str_replace_all(X8," ","")) %>%
  mutate(X9 = str_replace_all(X9," ","")) %>%
  mutate(X10 = str_replace_all(X10," ",""))

income1920$X7 <- as.numeric(income1920$X7)
income1920$X8 <- as.numeric(income1920$X8)
income1920$X9 <- as.numeric(income1920$X9)
income1920$X10 <- as.numeric(income1920$X10)
```

Stacking the five datasets and naming columns
```{r}
income1112 <- income1112 %>%
  mutate(X11 = 2012)
income1314 <- income1314 %>%
  mutate(X11 = 2014)
income1516 <- income1516 %>%
  mutate(X11 = 2016)
income1718 <- income1718 %>%
  mutate(X11 = 2018)
income1920 <- income1920 %>%
  mutate(X11 = 2020)

income_df <- bind_rows(income1112, income1314, income1516, income1718, income1920)

colnames(income_df) <- c("msoa",
                    "MSOA_name",
                    "local_authority_code",
                    "local_authority_name",
                    "region_code",
                    "region_name",
                    "total_annual_income",
                    "upper_confidence_limit",
                    "lower_confidence_limit",
                    "confidence_interval",
                    "year")
```

Data is recorded every two years and need to be duplicate for odd years and selecting columns
```{r}
income_df_odd <- income_df %>%
  mutate(year = year - 1)

income_df <- bind_rows(income_df, income_df_odd)

income_df <- income_df |>
  select(msoa, MSOA_name, region_name, total_annual_income, confidence_interval, year)
```

### Pollution data

Loading and stacking the datasets
```{r}
#| echo: false

pollution_2020 <- vroom(here("data", "pollution_2020.csv"))
pollution_2021 <- vroom(here("data", "pollution_2021.csv"))
pollution_2022 <- vroom(here("data", "pollution_2022.csv"))

pollution_df <- bind_rows(pollution_2020, pollution_2021, pollution_2022)
```

Select and rename columns + takes the average
```{r}
pollution_df <- pollution_df |>
  select(c("objectid",
           "name",
           "unique_code",
           "pollutant_metric",
           "maximum_value"))

pollution_df <- pollution_df %>%
  mutate(pollutant_metric = str_replace_all(pollutant_metric, "PM10 annual mean Limit Value 2020","2020")) %>%
  mutate(pollutant_metric = str_replace_all(pollutant_metric, "PM10 annual mean Limit Value 2021","2021")) %>%
  mutate(pollutant_metric = str_replace_all(pollutant_metric, "PM10 annual mean Limit Value 2022","2022"))

pollution_df <- pollution_df %>%
  rename("year"="pollutant_metric", "msoa"="unique_code", "local_authority_name"="name")

pollution_df <- pollution_df %>%
  group_by(local_authority_name) %>%
  summarize('PM10' = mean(maximum_value))
```

### Population data

Load and rename
```{r}
#| echo: false
population_df <- vroom(here("data", "population2011.csv"), skip = 1, col_names = FALSE)

population_df <- population_df %>%
  select(-3,-4) %>%
  rename("postcode" = "X1", "population" = "X2", "households" = "X5")

#write.csv(population_df,here("data","population_df.csv"))
```

### Postcode to area

```{r}
#| echo: false

postcode_df <- vroom(here("data", "postcode_to_area.csv"))

postcode_df <- postcode_df |>
  select(pcds, msoa21cd, ladnm) |>
  rename("postcode" = "pcds",
         "msoa" = "msoa21cd", 
         "local_authority_name" = "ladnm" )
```

## Merge to final dataframe and selection of the useful variables

```{r}
final_df <- df

final_df <- final_df %>%
  left_join(postcode_df, by = "postcode")

final_df <- final_df %>%
  left_join(population_df, by = "postcode")

final_df <- final_df %>%
  left_join(income_df, by = c("msoa","year"))

final_df <- final_df %>%
  left_join(pollution_df, by = "local_authority_name")

final_df <- final_df %>%
  select(-deed_date,
         -saon,
         -paon,
         -street,
         -locality,
         -transaction_category,
         -local_authority_name,
         -MSOA_name,
         -region_name)

saveRDS(final_df, here("data","full_final_df.rds"))
```


## Time series dataframe
### Import data and formating
```{r}
bank_rate_df <- vroom(here('data', 'bank_rate.csv'), delim = ',')
inflation_df <- vroom(here('data', 'inflation.csv'), col_names = FALSE, skip = 287, delim =',')

inflation_df <- inflation_df %>% 
  mutate(date = as.Date(paste0(X1, 1), format= "%Y %b%d")) %>%
  mutate(year = as.numeric(format(date, format="%Y")), 
         month = as.numeric(format(date, format="%m"))) %>%
  mutate(CPI = (X2)/(X2[1:1])*100) %>%
  select(year, month, CPI)

bank_rate_df <- bank_rate_df %>%
  slice(0:72) %>%
  mutate(date = as.Date(`Date Changed`, format=("%d %b %y"))) %>%
  mutate(year = as.numeric(format(date, format="%Y")), 
         month = as.numeric(format(date, format="%m"))) %>%
  select(year, month, "rate"=Rate)
```
### Merging
```{r}
time_df <- inflation_df %>%
  left_join(bank_rate_df, by = c("year","month")) %>%
  na.locf(na.rm=FALSE)

time_df[1,4] = 6.13

final_df <- readRDS(here('data', 'full_final_df.rds'))

price_nb_df <- final_df %>%
  group_by(year, month) %>%
  summarise(nb_transac = n(),
            mean_price = mean(price_paid))

price_nb_df <- price_nb_df %>%
  mutate(month, month = as.numeric(month))

time_df <- time_df %>%
  left_join(price_nb_df, by = c("year", "month"))

time_df <- time_df %>%
  mutate(real_price = (time_df$mean_price/time_df$CPI)*100) %>%
  mutate(date = lubridate::make_date(year = time_df$year, month = time_df$month, day = 1)) %>%
  select(-month, -year)

saveRDS(time_df, here("data","full_time_df.rds"))
```


```{r}
ggplot(time_df, aes(x=date)) +
  geom_line(aes(y = mean_price), color="steelblue") + 
  geom_line(aes(y = real_price), color="darkred")

ggplot(time_df, aes(x=date)) +
  geom_line(aes(y = nb_transac), color="steelblue")
```
## Population by MSOA
```{r}
pop_by_msoa <- postcode_df %>%
  left_join(population_df, by = "postcode")

pop_by_msoa <- pop_by_msoa %>%
  group_by(msoa) %>%
  mutate(pop = sum(population, na.rm=TRUE)) %>%
  na.omit() %>%
  distinct(msoa, .keep_all = TRUE) %>%
  select(-c("population", "postcode", "households"))
```

## MAP

```{r}
transac_msoa <- final_df %>%
  group_by(year, msoa) %>%
  summarise(mean_price = mean(price_paid), 
            nb_transac = n())

```


```{r}
library(geojsonio)
ukmap <- geojson_read(here('uk_local_areas', 'uk_la.geojson'), what = "sp")


library(broom)
ukmap_f <- tidy(ukmap)
```

```{r}
ggplot() +
  geom_polygon(data = ukmap_f, aes( x = long, y = lat, group = group), fill="blue", color="black") +
  theme_void() +
  coord_map()
```



## Clearing the environment

```{r}
#| echo: false

saveRDS(final_df,here("data","final_df.rds"))

rm(list=ls())

population_df <- vroom(here("data", "population_df.csv"))

final_df <- readRDS(here("data","final_df.rds"))

```

## Description of the variables in the final dataset

1) `r colnames(final_df[,1])` is the sale price stated on the transfer deed.

2) `r colnames(final_df[,2])` is the postcode used at the time of the transaction.

3) `r colnames(final_df[,3])` refers to the property type such that : D = Detached, S = Semi-Detached, T = Terraced, F = Flats/Maisonettes,O=Other

4) `r colnames(final_df[,4])` indicates the age of the property and applies to all price paid transactions,
residential and non-residential. Y = a newly built property, N = an established residential building.

5) `r colnames(final_df[,5])` relates to the tenure: F = Freehold, L= Leasehold

6 to 10) The name of the following variables are self-explanatory: `r colnames(final_df[,6])`, `r colnames(final_df[,7])`, `r colnames(final_df[,8])`, `r colnames(final_df[,9])`,`r colnames(final_df[,10])`.

11) `r colnames(final_df[,11])` indicates the Middle Layer Super Output Areas (MSOA), which is a geographic hierarchy designed to improve the reporting of small area statistics in England and Wales. The minimum population is 5000 and the mean is 7200.

12 and 13) `r colnames(final_df[,12])` and `r colnames(final_df[,13])` refers to the number of people and households sharing the same postcode. Even if those variables contains a lot of NAs (`r sum(is.na(final_df$population))` NAs), when we sum across all postcodes we obtain a total population of `r sum(population_df$population)`, which is roughly equal to the total population of England and Wales in 2011.

14) `r colnames(final_df[,14])` refers to the mean household disposable (net) income on an equivalised basis for middle layer super output areas (MSOAs) in England and Wales. Equivalisation is the process of accounting for the fact that households with many members are likely to need a higher income to achieve the same standard of living as households with fewer members.

15) `r colnames(final_df[,15])` is a 95% confidence interval for the income variable. It represents a range of values that a measure can take, based on statistical uncertainty and the fact that the data were derived from a sample of households across the country.

16) `r colnames(final_df[,16])` is a local measure of air pollution. Precisely, it measures the annual average across years from 2020 to 2022 of the air concentration in particulate matter (PM) of less than 10 Âµm in diameter

## Dataset information and descriptive statistics

Our main dataset consists of the description of `r nrow(final_df)` real estate transactions using `r ncol(final_df)` variables.

```{r}
#| echo: false

info_df <- final_df %>%
  summarize("Number of cities" = n_distinct(town), "Number of districts" = n_distinct(district), "Number of counties" = n_distinct(county))

info_df2 <- final_df %>%
  select(price_paid,year,population,households,total_annual_income,PM10) %>%
  summarize_all(list(mean = mean, median = median, min = min, max = max),na.rm = TRUE) %>%
  pivot_longer(cols = everything(), names_to = c(".value", "variable"), names_pattern = "(.+)_(.+)")

example_df <- final_df %>%
  head(n=10)

knitr::kable(example_df, digits = 0)

knitr::kable(info_df, align = "ccc", digits = 0)

knitr::kable(info_df2, caption = "Main descriptive statistics", align = "lrrrrrr", digits = 0)
```
## Graphical representation of our main variable

```{r}
#| echo: false

graph_df <- final_df %>%
  group_by(year) %>%
  summarise(num_transactions = n(),mean_price = mean(price_paid))
  
graph_df <- graph_df |>
  pivot_longer(cols = num_transactions:mean_price, names_to="variable", values_to="value")

ggplot(graph_df, aes(x = year, y = value)) + 
  geom_line() + 
  facet_wrap(~variable, scales = "free", ncol = 1) 
```


## Research question

Through this report, we want to explore the determinants of real estate transactions in England and Wales. We will do so by utilizing a diverse set of variables from a variety of government souces. 

Research Question:

What factors contribute to the variation in the number of real estate transactions in the United Kingdom, and to what extent do the location of the property, type of property, average income in the area, population density, and air quality influence these transactions?

First findings and proposal of further analysis: 

There is a clear drop in the number of transactions around the financial crisis of 2007. This was preceded by a stagnation in the average yearly price. The Quantitative Easing starting in 2015 could also explain the price peaking in the same year. 

Moreover, The number of transactions plummets in 2020 due to the covid crisis and is followed by a substantial rebound in 2021. Finally, it seems the year 2022 cannot be taken into account because we are missign data from the last months. 

Our future analysis will focus on: 

1) Producing a geographical analysis (using several maps and population density). 
2) Correcting the price evolution by the inflation rate. 
3) Look for seasonality in the evolution of price and number of transactions. 
4) Find correlations between socio-economic/environmental factors and our variables of interest. 







